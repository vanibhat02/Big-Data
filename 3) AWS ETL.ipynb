{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "# Glue Studio Notebook\n",
    "You are now running a **Glue Studio** notebook; before you can start using your notebook you *must* start an interactive session.\n",
    "\n",
    "## Available Magics\n",
    "|          Magic              |   Type       |                                                                        Description                                                                        |\n",
    "|-----------------------------|--------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| %%configure                 |  Dictionary  |  A json-formatted dictionary consisting of all configuration parameters for a session. Each parameter can be specified here or through individual magics. |\n",
    "| %profile                    |  String      |  Specify a profile in your aws configuration to use as the credentials provider.                                                                          |\n",
    "| %iam_role                   |  String      |  Specify an IAM role to execute your session with.                                                                                                        |\n",
    "| %region                     |  String      |  Specify the AWS region in which to initialize a session                                                                                                  |\n",
    "| %session_id                 |  String      |  Returns the session ID for the running session.                                                                                                          |\n",
    "| %connections                |  List        |  Specify a comma separated list of connections to use in the session.                                                                                     |\n",
    "| %additional_python_modules  |  List        |  Comma separated list of pip packages, s3 paths or private pip arguments.                                                                                 |\n",
    "| %extra_py_files             |  List        |  Comma separated list of additional Python files from S3.                                                                                                 |\n",
    "| %extra_jars                 |  List        |  Comma separated list of additional Jars to include in the cluster.                                                                                       |\n",
    "| %number_of_workers          |  Integer     |  The number of workers of a defined worker_type that are allocated when a job runs. worker_type must be set too.                                          |\n",
    "| %worker_type                |  String      |  Standard, G.1X, *or* G.2X. number_of_workers must be set too. Default is G.1X                                                                            |\n",
    "| %glue_version               |  String      |  The version of Glue to be used by this session. Currently, the only valid options are 2.0 and 3.0 (eg: %glue_version 2.0)                                |\n",
    "| %security_config            |  String      |  Define a security configuration to be used with this session.                                                                                            |\n",
    "| %sql                        |  String      |  Run SQL code. All lines after the initial %%sql magic will be passed as part of the SQL code.                                                            |\n",
    "| %streaming                  |  String      |  Changes the session type to Glue Streaming.                                                                                                              |\n",
    "| %etl                        |  String      |   Changes the session type to Glue ETL.                                                                                                                   |\n",
    "| %status                     |              |  Returns the status of the current Glue session including its duration, configuration and executing user / role.                                          |\n",
    "| %stop_session               |              |  Stops the current session.                                                                                                                               |\n",
    "| %list_sessions              |              |  Lists all currently running sessions by name and ID.                                                                                                     |\n",
    "| %spark_conf                 |  String      |  Specify custom spark configurations for your session. E.g. %spark_conf spark.serializer=org.apache.spark.serializer.KryoSerializer                       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Glue Interactive Sessions Kernel\n",
      "For more information on available magic commands, please type %help in any new cell.\n",
      "\n",
      "Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
      "Installed kernel version: 0.35 \n",
      "Authenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::098960867156:role/aws-glue-role-project-combinedRole\n",
      "Trying to create a Glue session for the kernel.\n",
      "Worker Type: G.1X\n",
      "Number of Workers: 5\n",
      "Session ID: fa36d89c-4adb-458f-bcfc-9af9ab73a96b\n",
      "Applying the following default arguments:\n",
      "--glue_kernel_version 0.35\n",
      "--enable-glue-datacatalog true\n",
      "Waiting for session fa36d89c-4adb-458f-bcfc-9af9ab73a96b to get into ready status...\n",
      "Session fa36d89c-4adb-458f-bcfc-9af9ab73a96b has been created\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Parameters\n",
    "glue_db = \"pyspark_tutorial_db\"\n",
    "zillow_tbl = \"zillow\"\n",
    "s3_write_path = \"s3://aws-glue-bucket-project-combined/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "|-- zpid: string\n",
      "|-- id: choice\n",
      "|    |-- long\n",
      "|    |-- string\n",
      "|-- providerlistingid: choice\n",
      "|    |-- long\n",
      "|    |-- string\n",
      "|-- imgsrc: string\n",
      "|-- hasimage: string\n",
      "|-- detailurl: string\n",
      "|-- statustype: string\n",
      "|-- statustext: string\n",
      "|-- countrycurrency: string\n",
      "|-- price: string\n",
      "|-- unformattedprice: string\n",
      "|-- address: string\n",
      "|-- addressstreet: string\n",
      "|-- addresscity: string\n",
      "|-- addressstate: string\n",
      "|-- addresszipcode: string\n",
      "|-- isundisclosedaddress: string\n",
      "|-- beds: string\n",
      "|-- baths: string\n",
      "|-- areacode: string\n",
      "|-- latlong: string\n",
      "|-- iszillowowned: string\n",
      "|-- variabledata: string\n",
      "|-- badgeinfo: string\n",
      "|-- hdpdata: string\n",
      "|-- issaved: string\n",
      "|-- hasopenhouse: string\n",
      "|-- openhousestartdate: string\n",
      "|-- openhouseenddate: string\n",
      "|-- openhousedescription: string\n",
      "|-- isuserclaimingowner: string\n",
      "|-- isuserconfirmedclaim: string\n",
      "|-- pgapt: string\n",
      "|-- sgapt: string\n",
      "|-- estimated annual cost: string\n",
      "|-- shouldshowzestimateasprice: string\n",
      "|-- has3dmodel: string\n",
      "|-- hasvideo: string\n",
      "|-- ishomerec: string\n",
      "|-- hasadditionalattributions: string\n",
      "|-- isfeaturedlisting: string\n",
      "|-- availabilitydate: string\n",
      "|-- list: string\n",
      "|-- relaxed: string\n",
      "|-- brokername: string\n",
      "|-- info6string: string\n",
      "|-- lotareastring: string\n",
      "|-- buildername: string\n",
      "|-- streetviewmetadataurl: string\n",
      "|-- streetviewurl: string\n",
      "|-- ispropertyresultcdp: string\n",
      "|-- best_deal: string\n",
      "|-- homeinfo_streetaddress: string\n",
      "|-- homeinfo_latitude: string\n",
      "|-- homeinfo_longitude: string\n",
      "|-- homeinfo_price: string\n",
      "|-- homeinfo_hometype: string\n",
      "|-- homeinfo_lotareavalue: string\n",
      "|-- homeinfo_lotareaunit: string\n"
     ]
    }
   ],
   "source": [
    "#Read Zillow listings data to Glue dynamic frame\n",
    "df1 = glueContext.create_dynamic_frame.from_catalog(database = glue_db, table_name = zillow_tbl )\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "|-- zpid: string\n",
      "|-- imgsrc: string\n",
      "|-- hasimage: string\n",
      "|-- detailurl: string\n",
      "|-- statustext: string\n",
      "|-- price: string\n",
      "|-- unformattedprice: string\n",
      "|-- address: string\n",
      "|-- addressstreet: string\n",
      "|-- addresscity: string\n",
      "|-- addressstate: string\n",
      "|-- addresszipcode: string\n",
      "|-- beds: string\n",
      "|-- baths: string\n",
      "|-- areacode: string\n",
      "|-- hasopenhouse: string\n",
      "|-- openhousedescription: string\n",
      "|-- estimated annual cost: string\n",
      "|-- has3dmodel: string\n",
      "|-- hasadditionalattributions: string\n",
      "|-- brokername: string\n",
      "|-- homeinfo_latitude: string\n",
      "|-- homeinfo_longitude: string\n",
      "|-- homeinfo_hometype: string\n",
      "|-- homeinfo_lotareavalue: string\n",
      "|-- homeinfo_lotareaunit: string\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "df1=df1.drop_fields([\"id\",\"providerlistingid\",\"countrycurrency\", \"statustype\",\"isundisclosedaddress\", \"latlong\",\"iszillowowned\",\"variabledata\",\"badgeinfo\",\"hdpdata\", \"issaved\", \"openhousestartdate\", \"openhouseenddate\",\"isuserclaimingowner\",\"pgapt\",\"sgapt\", \"shouldshowzestimateasprice\", \n",
    "\"hasvideo\", \"ishomerec\",\"availabilitydate\" ,\"list\" , \"relaxed\" ,  \"info6string\" , \"lotareastring\",\"buildername\" , \"ispropertyresultcdp\" , \"streetviewmetadataurl\" , \"streetviewurl\",\"best_deal\" , \"homeinfo_streetaddress\", \"homeinfo_price\", \"isuserconfirmedclaim\", \"isfeaturedlisting\"])\n",
    "\n",
    "# print the data schema\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7873\n"
     ]
    }
   ],
   "source": [
    "# Finding the number of records\n",
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert dynamic frame to data frame to use standard pyspark functions\n",
    "data_frame = df1.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7873\n"
     ]
    }
   ],
   "source": [
    "# By using ‘any’, drop a row if it contains NULLs on any columns.\n",
    "data_frame.na.drop(how=\"any\")\n",
    "\n",
    "# Validating for nulls in the dartaset and counting the rows post the nulls removal\n",
    "data_frame.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7873\n"
     ]
    }
   ],
   "source": [
    "# drop duplicate rows\n",
    "data_frame.dropDuplicates() \n",
    "\n",
    "# Finding the count of number of records post the removal\n",
    "data_frame.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7492\n"
     ]
    }
   ],
   "source": [
    "# Removing North Carolina house listings from the dataset as we analyze California listings\n",
    "data_frame = data_frame.filter(((data_frame.addressstate != 'NC')))\n",
    "\n",
    "# Finding the count of number of records post the removal\n",
    "data_frame.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Few NC records are observed and removed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "data_frame=data_frame.withColumn(\"homeinfo_lotareavalue\",when(data_frame.homeinfo_lotareaunit == \"acres\",data_frame.homeinfo_lotareavalue*43560)\n",
    "                   .otherwise(data_frame.homeinfo_lotareavalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# convert home_AreaUnit having acres to sqft\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "data_frame=data_frame.withColumn('homeinfo_lotareaunit', when(data_frame.homeinfo_lotareaunit== 'acres', 'sqft')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+--------+---------+----------+-----+----------------+-------+-------------+-----------+------------+--------------+----+-----+--------+------------+--------------------+---------------------+----------+-------------------------+----------+-----------------+------------------+-----------------+---------------------+--------------------+\n",
      "|zpid|imgsrc|hasimage|detailurl|statustext|price|unformattedprice|address|addressstreet|addresscity|addressstate|addresszipcode|beds|baths|areacode|hasopenhouse|openhousedescription|estimated annual cost|has3dmodel|hasadditionalattributions|brokername|homeinfo_latitude|homeinfo_longitude|homeinfo_hometype|homeinfo_lotareavalue|homeinfo_lotareaunit|\n",
      "+----+------+--------+---------+----------+-----+----------------+-------+-------------+-----------+------------+--------------+----+-----+--------+------------+--------------------+---------------------+----------+-------------------------+----------+-----------------+------------------+-----------------+---------------------+--------------------+\n",
      "+----+------+--------+---------+----------+-----+----------------+-------+-------------+-----------+------------+--------------+----+-----+--------+------------+--------------------+---------------------+----------+-------------------------+----------+-----------------+------------------+-----------------+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "data_frame.filter(((data_frame.homeinfo_lotareaunit == \"acres\"))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame = data_frame.withColumn(\"addresszipcode\", data_frame.addresszipcode.cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------+--------------------+-------------------+-----------+----------------+--------------------+-------------+-------------+------------+--------------+----+-----+--------+------------+--------------------+---------------------+----------+-------------------------+--------------------+-----------------+------------------+-----------------+---------------------+--------------------+\n",
      "|     zpid|              imgsrc|hasimage|           detailurl|         statustext|      price|unformattedprice|             address|addressstreet|  addresscity|addressstate|addresszipcode|beds|baths|areacode|hasopenhouse|openhousedescription|estimated annual cost|has3dmodel|hasadditionalattributions|          brokername|homeinfo_latitude|homeinfo_longitude|homeinfo_hometype|homeinfo_lotareavalue|homeinfo_lotareaunit|\n",
      "+---------+--------------------+--------+--------------------+-------------------+-----------+----------------+--------------------+-------------+-------------+------------+--------------+----+-----+--------+------------+--------------------+---------------------+----------+-------------------------+--------------------+-----------------+------------------+-----------------+---------------------+--------------------+\n",
      "|     zpid|              imgSrc|hasImage|           detailUrl|         statusText|      price|unformattedPrice|             address|addressStreet|  addressCity|addressState|          null|beds|baths|    area|hasOpenHouse|openHouseDescription|            zestimate|has3DModel|     hasAdditionalAttr...|          BrokerName|homeInfo_latitude|homeInfo_longitude|homeInfo_homeType| homeInfo_lotAreaV...|                null|\n",
      "|125161028|https://photos.zi...|    TRUE|https://www.zillo...|Lot / Land for sale|   $24,000 |           24000|Bancroft Ave, San...| Bancroft Ave|San francisco|          CA|         94124|   0|    0|       0|       FALSE|                   0|               954500|     FALSE|                     TRUE|Corcoran Global L...|        37.724983|        -122.39172|              LOT|   15002.063999999998|                sqft|\n",
      "| 83152704|https://photos.zi...|    TRUE|https://www.zillo...|     Condo for sale|$1,250,000 |         1250000|3471 19th St, San...| 3471 19th St|San Francisco|          CA|         94110|   3|    2|    1778|       FALSE|                   0|              1895000|     FALSE|                     TRUE|             Compass|         37.75993|        -122.42086|            CONDO|             2125.728|                null|\n",
      "+---------+--------------------+--------+--------------------+-------------------+-----------+----------------+--------------------+-------------+-------------+------------+--------------+----+-----+--------+------------+--------------------+---------------------+----------+-------------------------+--------------------+-----------------+------------------+-----------------+---------------------+--------------------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "data_frame.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# School Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Parameters\n",
    "glue_db = \"pyspark_tutorial_db\"\n",
    "school_tbl = \"school\"\n",
    "s3_write_path = \"s3://aws-glue-bucket-project-combined/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "|-- school code: string\n",
      "|-- school name: string\n",
      "|-- name: string\n",
      "|-- address: string\n",
      "|-- city: string\n",
      "|-- state: string\n",
      "|-- zip: string\n",
      "|-- zip4: string\n",
      "|-- population: choice\n",
      "|    |-- long\n",
      "|    |-- string\n",
      "|-- county: string\n",
      "|-- countyfips: choice\n",
      "|    |-- long\n",
      "|    |-- string\n",
      "|-- latitude: string\n",
      "|-- longitude: string\n",
      "|-- level_: string\n",
      "|-- enrollment: string\n",
      "|-- st_grade: string\n",
      "|-- end_grade: string\n",
      "|-- districtid: choice\n",
      "|    |-- long\n",
      "|    |-- string\n",
      "|-- ft_teacher: string\n",
      "|-- statewide rankå(2019): string\n",
      "|-- statewide rank(2018): choice\n",
      "|    |-- int\n",
      "|    |-- string\n",
      "|-- statewide rank(2017): choice\n",
      "|    |-- int\n",
      "|    |-- string\n",
      "|-- similar students rank(2019): string\n",
      "|-- similar students rank(2018): choice\n",
      "|    |-- int\n",
      "|    |-- string\n",
      "|-- similar students rank(2017): choice\n",
      "|    |-- int\n",
      "|    |-- string\n",
      "|-- college/career percent prepared (2019): string\n",
      "|-- college/career percent prepared (2018): choice\n",
      "|    |-- int\n",
      "|    |-- string\n",
      "|-- college/career percent prepared (2017): choice\n",
      "|    |-- int\n",
      "|    |-- string\n",
      "|-- growth(2017-2019): choice\n",
      "|    |-- long\n",
      "|    |-- string\n",
      "|-- school district: string\n",
      "|-- authorizer: string\n",
      "|-- school type: string\n",
      "|-- statewide percentile(2019): string\n",
      "|-- statewide percentile(2018): choice\n",
      "|    |-- int\n",
      "|    |-- string\n",
      "|-- statewide percentile(2017): choice\n",
      "|    |-- int\n",
      "|    |-- string\n"
     ]
    }
   ],
   "source": [
    "#Read school data to Glue dynamic frame\n",
    "df2 = glueContext.create_dynamic_frame.from_catalog(database = glue_db, table_name = school_tbl )\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# drop unnecessary columns\n",
    "df2 = df2.drop_fields(paths= [ \"name\",\"population\", \"countyfips\",\"districtid\", \"school type\",\n",
    " \"statewide rank(2018)\",\"statewide rank(2017)\", \"similar students rank(2018)\",\"similar students rank(2017)\", \n",
    " \"college/career percent prepared (2018)\",\"college/career percent prepared (2017)\",\"growth(2017-2019)\", \"statewide percentile(2018)\", \"statewide percentile(2017)\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "|-- school code: string\n",
      "|-- school name: string\n",
      "|-- address: string\n",
      "|-- city: string\n",
      "|-- state: string\n",
      "|-- zip: string\n",
      "|-- zip4: string\n",
      "|-- county: string\n",
      "|-- latitude: string\n",
      "|-- longitude: string\n",
      "|-- level_: string\n",
      "|-- enrollment: string\n",
      "|-- st_grade: string\n",
      "|-- end_grade: string\n",
      "|-- ft_teacher: string\n",
      "|-- statewide rankå(2019): string\n",
      "|-- similar students rank(2019): string\n",
      "|-- college/career percent prepared (2019): string\n",
      "|-- school district: string\n",
      "|-- authorizer: string\n",
      "|-- statewide percentile(2019): string\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10577\n"
     ]
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert dynamic frame to data frame to use standard pyspark functions\n",
    "data_frame_school = df2.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[school code: string, school name: string, address: string, city: string, state: string, zip: string, zip4: string, county: string, latitude: string, longitude: string, level_: string, enrollment: string, st_grade: string, end_grade: string, ft_teacher: string, statewide rankå(2019): string, similar students rank(2019): string, college/career percent prepared (2019): string, school district: string, authorizer: string, statewide percentile(2019): string]\n"
     ]
    }
   ],
   "source": [
    "# By using ‘any’, drop a row if it contains NULLs on any columns.\n",
    "data_frame_school.na.drop(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[school code: string, school name: string, address: string, city: string, state: string, zip: string, zip4: string, county: string, latitude: string, longitude: string, level_: string, enrollment: string, st_grade: string, end_grade: string, ft_teacher: string, statewide rankå(2019): string, similar students rank(2019): string, college/career percent prepared (2019): string, school district: string, authorizer: string, statewide percentile(2019): string]\n"
     ]
    }
   ],
   "source": [
    "# drop duplicate rows\n",
    "data_frame_school.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8922\n"
     ]
    }
   ],
   "source": [
    "# Filter with CA States ( 8922 )\n",
    "data_frame_school = data_frame_school.filter(((data_frame_school.state == \"CA\")))\n",
    "\n",
    "data_frame_school.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame_school = data_frame_school.withColumn(\"enrollment\", data_frame_school.enrollment.cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8815\n"
     ]
    }
   ],
   "source": [
    "# Filler columns by excluding enrollment = -999 and #N/A\n",
    "data_frame_school = data_frame_school.filter(((data_frame_school.enrollment !=-999)))\n",
    "data_frame_school.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename columns for more clarity\n",
    "data_frame_school = data_frame_school.withColumnRenamed(\"school code\",\"school_code\") \\\n",
    "     .withColumnRenamed(\"school name\",\"school_name\")\\\n",
    "     .withColumnRenamed(\"address\",\"school_address\")\\\n",
    "     .withColumnRenamed(\"city\",\"school_city\")\\\n",
    "     .withColumnRenamed(\"state\",\"school_state\")\\\n",
    "     .withColumnRenamed(\"zip\",\"school_zipcode\")\\\n",
    "     .withColumnRenamed(\"zip4\",\"school_areacode\")\\\n",
    "     .withColumnRenamed(\"county\",\"school_county\")\\\n",
    "     .withColumnRenamed(\"latitude\",\"school_latitude\")\\\n",
    "     .withColumnRenamed(\"longitude\",\"school_longitude\")\\\n",
    "     .withColumnRenamed(\"level_\",\"school_type\")\\\n",
    "     .withColumnRenamed(\"statewide rankå(2019)\",\"statewide_rank\")\\\n",
    "     .withColumnRenamed(\"similar students rank(2019)\",\"similar_students_rank\")\\\n",
    "     .withColumnRenamed(\"college/career percent prepared (2019)\",\"college_career_percent_prepared\")\\\n",
    "     .withColumnRenamed(\"school district\",\"school_district\")\\\n",
    "     .withColumnRenamed(\"statewide percentile(2019)\",\"statewide_percentile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- school_code: string (nullable = true)\n",
      " |-- school_name: string (nullable = true)\n",
      " |-- school_address: string (nullable = true)\n",
      " |-- school_city: string (nullable = true)\n",
      " |-- school_state: string (nullable = true)\n",
      " |-- school_zipcode: string (nullable = true)\n",
      " |-- school_areacode: string (nullable = true)\n",
      " |-- school_county: string (nullable = true)\n",
      " |-- school_latitude: string (nullable = true)\n",
      " |-- school_longitude: string (nullable = true)\n",
      " |-- school_type: string (nullable = true)\n",
      " |-- enrollment: float (nullable = true)\n",
      " |-- st_grade: string (nullable = true)\n",
      " |-- end_grade: string (nullable = true)\n",
      " |-- ft_teacher: string (nullable = true)\n",
      " |-- statewide_rank: string (nullable = true)\n",
      " |-- similar_students_rank: string (nullable = true)\n",
      " |-- college_career_percent_prepared: string (nullable = true)\n",
      " |-- school_district: string (nullable = true)\n",
      " |-- authorizer: string (nullable = true)\n",
      " |-- statewide_percentile: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "data_frame_school.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+---------------+-----------+------------+--------------+---------------+-------------+---------------+----------------+-----------+----------+--------+---------+----------+--------------+---------------------+-------------------------------+--------------------+------------------+--------------------+\n",
      "|school_code|         school_name| school_address|school_city|school_state|school_zipcode|school_areacode|school_county|school_latitude|school_longitude|school_type|enrollment|st_grade|end_grade|ft_teacher|statewide_rank|similar_students_rank|college_career_percent_prepared|     school_district|        authorizer|statewide_percentile|\n",
      "+-----------+--------------------+---------------+-----------+------------+--------------+---------------+-------------+---------------+----------------+-----------+----------+--------+---------+----------+--------------+---------------------+-------------------------------+--------------------+------------------+--------------------+\n",
      "|     129882|21st Century Lear...|939 E. 10TH ST.|   BEAUMONT|          CA|         92223|           1927|    Riverside|    33.93528012|    -116.9693181|      OTHER|      65.0|      KG|       12|         4|              |                     |                           0.13|Beaumont Unified ...|  Beaumont Unified|                    |\n",
      "|    6027767|A. E. Arnold Elem...| 9281 DENNI ST.|    CYPRESS|          CA|         90630|           2724|       Orange|    33.82718596|    -118.0556012| ELEMENTARY|     740.0|      KG|        6|        29|             9|                    4|                               |Cypress Elementar...|Cypress Elementary|                  81|\n",
      "+-----------+--------------------+---------------+-----------+------------+--------------+---------------+-------------+---------------+----------------+-----------+----------+--------+---------+----------+--------------+---------------------+-------------------------------+--------------------+------------------+--------------------+\n",
      "only showing top 2 rows\n"
     ]
    }
   ],
   "source": [
    "data_frame_school.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame_school = data_frame_school.repartition(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate School Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum,avg,max,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing datatypes wherever required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame_school = data_frame_school.withColumn(\"statewide_rank\", data_frame_school.statewide_rank.cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame_school = data_frame_school.withColumn(\"school_zipcode\", data_frame_school.school_zipcode.cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame_school_aggr=data_frame_school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame_school_aggr = data_frame_school.groupBy(\"school_zipcode\").agg(sum(\"enrollment\").alias(\"Sum School Enrollment\"),\\\n",
    "                                                                                   avg('statewide_rank').alias(\"Avg School Rank\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------+------------------+\n",
      "|school_zipcode|Sum School Enrollment|   Avg School Rank|\n",
      "+--------------+---------------------+------------------+\n",
      "|         93560|               2724.0|               1.5|\n",
      "|         95127|              10918.0|4.3478260869565215|\n",
      "+--------------+---------------------+------------------+\n",
      "only showing top 2 rows\n"
     ]
    }
   ],
   "source": [
    "data_frame_school_aggr.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|avg(Avg School Rank)|\n",
      "+--------------------+\n",
      "|   5.678037946710747|\n",
      "+--------------------+\n"
     ]
    }
   ],
   "source": [
    "avg=data_frame_school_aggr.agg(avg('Avg School Rank')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------+------------------+\n",
      "|school_zipcode|Sum School Enrollment|   Avg School Rank|\n",
      "+--------------+---------------------+------------------+\n",
      "|         93560|               2724.0|               1.5|\n",
      "|         95127|              10918.0|4.3478260869565215|\n",
      "|         95476|               4177.0| 4.111111111111111|\n",
      "|         94553|               3862.0|               6.4|\n",
      "|         91352|               9385.0| 3.727272727272727|\n",
      "|         90019|               4065.0|             4.375|\n",
      "|         92704|              14937.0|               4.0|\n",
      "|         91007|               6460.0| 9.833333333333334|\n",
      "|         93021|               7644.0|              8.25|\n",
      "|         94303|               2263.0|               3.8|\n",
      "|         93727|              12855.0| 4.714285714285714|\n",
      "|         92835|               2022.0| 9.333333333333334|\n",
      "|         94558|              11150.0|               6.0|\n",
      "|         92233|               1091.0| 4.666666666666667|\n",
      "|         92236|               5538.0|             4.125|\n",
      "|         95446|                 16.0|               2.0|\n",
      "|         91367|               7875.0| 7.166666666666667|\n",
      "|         95709|                466.0|               7.0|\n",
      "|         91905|                129.0|               7.0|\n",
      "|         91362|               6203.0|               8.0|\n",
      "+--------------+---------------------+------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "data_frame_school_aggr.na.fill(value=5.678).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Join house data and school data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_housing_school=data_frame.join(data_frame_school_aggr,data_frame.addresszipcode ==  data_frame_school_aggr.school_zipcode,\"left\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------+--------------------+--------------+-----------+----------------+--------------------+-----------------+--------------+------------+--------------+----+-----+--------+------------+--------------------+---------------------+----------+-------------------------+--------------------+-----------------+------------------+-----------------+---------------------+--------------------+--------------+---------------------+---------------+\n",
      "|    zpid|              imgsrc|hasimage|           detailurl|    statustext|      price|unformattedprice|             address|    addressstreet|   addresscity|addressstate|addresszipcode|beds|baths|areacode|hasopenhouse|openhousedescription|estimated annual cost|has3dmodel|hasadditionalattributions|          brokername|homeinfo_latitude|homeinfo_longitude|homeinfo_hometype|homeinfo_lotareavalue|homeinfo_lotareaunit|school_zipcode|Sum School Enrollment|Avg School Rank|\n",
      "+--------+--------------------+--------+--------------------+--------------+-----------+----------------+--------------------+-----------------+--------------+------------+--------------+----+-----+--------+------------+--------------------+---------------------+----------+-------------------------+--------------------+-----------------+------------------+-----------------+---------------------+--------------------+--------------+---------------------+---------------+\n",
      "|15585386|https://photos.zi...|    TRUE|https://www.zillo...|House for sale|$1,400,000 |         1400000|2033 Poplar Ave, ...|  2033 Poplar Ave|East Palo Alto|          CA|         94303|   3|    4|    2660|        TRUE|Open House - 2:00...|              1400006|     FALSE|                    FALSE|Keller Williams R...|        37.465576|       -122.150505|    SINGLE_FAMILY|             6198.588|                null|         94303|               2263.0|            3.8|\n",
      "|15584936|https://photos.zi...|    TRUE|https://www.zillo...|House for sale|$1,100,000 |         1100000|1395 Kavanaugh Dr...|1395 Kavanaugh Dr|East Palo Alto|          CA|         94303|   3|    2|    1100|       FALSE|                   0|              1091000|     FALSE|                    FALSE|Keller Williams R...|        37.475365|        -122.14615|    SINGLE_FAMILY|                 6534|                null|         94303|               2263.0|            3.8|\n",
      "|15585386|https://photos.zi...|    TRUE|https://www.zillo...|House for sale|$1,400,000 |         1400000|2033 Poplar Ave, ...|  2033 Poplar Ave|East Palo Alto|          CA|         94303|   3|    4|    2660|        TRUE|Open House - 2:00...|              1400006|     FALSE|                    FALSE|Keller Williams R...|        37.465576|       -122.150505|    SINGLE_FAMILY|             6198.588|                null|         94303|               2263.0|            3.8|\n",
      "+--------+--------------------+--------+--------------------+--------------+-----------+----------------+--------------------+-----------------+--------------+------------+--------------+----+-----+--------+------------+--------------------+---------------------+----------+-------------------------+--------------------+-----------------+------------------+-----------------+---------------------+--------------------+--------------+---------------------+---------------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "dataframe_housing_school.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- zpid: string (nullable = true)\n",
      " |-- imgsrc: string (nullable = true)\n",
      " |-- hasimage: string (nullable = true)\n",
      " |-- detailurl: string (nullable = true)\n",
      " |-- statustext: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- unformattedprice: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- addressstreet: string (nullable = true)\n",
      " |-- addresscity: string (nullable = true)\n",
      " |-- addressstate: string (nullable = true)\n",
      " |-- addresszipcode: integer (nullable = true)\n",
      " |-- beds: string (nullable = true)\n",
      " |-- baths: string (nullable = true)\n",
      " |-- areacode: string (nullable = true)\n",
      " |-- hasopenhouse: string (nullable = true)\n",
      " |-- openhousedescription: string (nullable = true)\n",
      " |-- estimated annual cost: string (nullable = true)\n",
      " |-- has3dmodel: string (nullable = true)\n",
      " |-- hasadditionalattributions: string (nullable = true)\n",
      " |-- brokername: string (nullable = true)\n",
      " |-- homeinfo_latitude: string (nullable = true)\n",
      " |-- homeinfo_longitude: string (nullable = true)\n",
      " |-- homeinfo_hometype: string (nullable = true)\n",
      " |-- homeinfo_lotareavalue: string (nullable = true)\n",
      " |-- homeinfo_lotareaunit: string (nullable = true)\n",
      " |-- school_zipcode: integer (nullable = true)\n",
      " |-- Sum School Enrollment: double (nullable = true)\n",
      " |-- Avg School Rank: double (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "dataframe_housing_school.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- school_code: string (nullable = true)\n",
      " |-- school_name: string (nullable = true)\n",
      " |-- school_address: string (nullable = true)\n",
      " |-- school_city: string (nullable = true)\n",
      " |-- school_state: string (nullable = true)\n",
      " |-- school_zipcode: integer (nullable = true)\n",
      " |-- school_areacode: string (nullable = true)\n",
      " |-- school_county: string (nullable = true)\n",
      " |-- school_latitude: string (nullable = true)\n",
      " |-- school_longitude: string (nullable = true)\n",
      " |-- school_type: string (nullable = true)\n",
      " |-- enrollment: float (nullable = true)\n",
      " |-- st_grade: string (nullable = true)\n",
      " |-- end_grade: string (nullable = true)\n",
      " |-- ft_teacher: string (nullable = true)\n",
      " |-- statewide_rank: float (nullable = true)\n",
      " |-- similar_students_rank: string (nullable = true)\n",
      " |-- college_career_percent_prepared: string (nullable = true)\n",
      " |-- school_district: string (nullable = true)\n",
      " |-- authorizer: string (nullable = true)\n",
      " |-- statewide_percentile: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "data_frame_school.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_housing_school = dataframe_housing_school.repartition(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert back to dynamic frame\n",
    "dynamic_frame_combined = DynamicFrame.fromDF(dataframe_housing_school, glueContext, \"dynamic_frame_write\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<awsglue.dynamicframe.DynamicFrame object at 0x7fafbcc774d0>\n"
     ]
    }
   ],
   "source": [
    "#Write data back to S3\n",
    "glueContext.write_dynamic_frame.from_options(\n",
    "    frame = dynamic_frame_combined,\n",
    "    connection_type = \"s3\",\n",
    "    connection_options = {\n",
    "        \"path\": s3_write_path,\n",
    "    },\n",
    "    format = \"csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<awsglue.dynamicframe.DynamicFrame object at 0x7fafbe2b4310>\n"
     ]
    }
   ],
   "source": [
    "#Convert back to dynamic frame\n",
    "dynamic_frame_school = DynamicFrame.fromDF(data_frame_school, glueContext, \"dynamic_frame_write\")\n",
    "\n",
    "#Write data back to S3\n",
    "glueContext.write_dynamic_frame.from_options(\n",
    "    frame = dynamic_frame_school,\n",
    "    connection_type = \"s3\",\n",
    "    connection_options = {\n",
    "        \"path\": s3_write_path,\n",
    "    },\n",
    "    format = \"csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
